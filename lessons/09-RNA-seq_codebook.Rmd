---
output: html_document
editor_options:
  chunk_output_type: console
---
# Codebook answers
30 total points


```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## DGE analysis overview

**.md file = 01-DGE_setup_and_overview.md**

### Setting up

#### Loading libraries
```{r, message = FALSE}

library(tidyverse)
library(RColorBrewer)
library(DESeq2)
library(pheatmap)
library(ggplot2)
library(ggrepel)

```

#### Loading data
```{r}

data <- read.delim("data/Mov10_full_counts.txt", row.names = 1)

meta <- read.delim("meta/Mov10_full_meta.txt", row.names = 1)
```

Use class() to inspect our data and make sure we are working with data frames:
```{r}
### Check classes of the data we just brought in
class(meta)
class(data)
```

#### Viewing data

```{r}

head(meta)

head(data[,1:5])

```

### DGE analysis workflow

#### RNA-seq count distribution

To determine the appropriate statistical model, we need information about the distribution of counts. To get an idea about how RNA-seq counts are distributed, let’s plot the counts for a single sample, ‘Mov10_oe_1’:
```{r}
ggplot(data) +
geom_histogram(aes(x = Mov10_oe_1), stat = "bin", bins = 200) +
  xlab("Raw expression counts") +
  ylab("Number of genes")
```

If we zoom in close to zero, we can see a large number of genes with counts of zero:
```{r}
ggplot(data) +
geom_histogram(aes(x = Mov10_oe_1), stat = "bin", bins = 200) +
   xlim(-5, 500)  +
   xlab("Raw expression counts") +
   ylab("Number of genes")
```

These images illustrate some common features of RNA-seq count data, including a low number of counts associated with a large proportion of genes, and a long right tail due to the lack of any upper limit for expression.

#### Modeling count data

By plotting the *mean versus the variance* of our data we should be able to see that the variance > mean and therefore it does not fit the Poisson distribution and is better suited to the Negative Binomial (NB) model.

To calculate the mean and variance of our data, we will use the `apply` function. The `apply` function allows you to apply a function to the margins (rows or columns) of a matrix. The syntax for `apply` is as follows: `apply(X, MARGIN, FUN)`, where `X` is a matrix, `MARGIN` is the margin of the matrix to apply the function to (1 = rows, 2 = columns), and `FUN` is the function to apply. 

We will use `MARGIN = 1` to apply the mean and variance of the counts for each row (gene) across the 'Mov10 overexpression' replicates. We will then create a data frame with the mean and variance of the counts for each gene.
```{r}

mean_counts <- apply(data[, 3:5], 1, mean)

variance_counts <- apply(data[, 3:5], 1, var)

# for ggplot we need the data to be in a data.frame
df <- data.frame(mean_counts, variance_counts)
```

Run the following code to plot the *mean versus variance* for the 'Mov10 overexpression' replicates:
```{r}

ggplot(df) +
  geom_point(aes(x = mean_counts, y = variance_counts)) +
  geom_line(aes(x = mean_counts, y = mean_counts, color = "red")) +
  scale_y_log10() +
  scale_x_log10()
```

Note that in the above figure, the variance across replicates tends to be greater than the mean (slope > 1, red line), especially for genes with large mean expression levels. This is a good indication that our data do not fit the Poisson distribution and we need to account for this increase in variance using the Negative Binomial model.

## Count normalization

**.md file = 02-DGE_count_normalization.md**


### Normalization

The steps for DESeq2 median of ratios method:

1. **calculate the geometric mean of each row in the count matrix**

2. **divide each row by the row's geometric mean**

3. **take the median value for each column -- these are your size factors, one for each sample**

4. **divide each sample by its size factor**

**Normalized Counts**

**Exercise** (in class)

Manually compute the size factors for our count matrix, then normalize the matrix.

Formula for geometric mean:
```{r}
# Geometric mean function: multiply all values in a vector and take the nth root of the product
geomean <- function(x, na.rm = TRUE){
    geo <- prod(x, na.rm = na.rm)^(1/length(x))
    
}

# OR the equivalent

geomean <- function(x, na.rm = TRUE){
    geo = exp(log(prod(x)^(1/length(x))))
    # (1/length(x)) * log(prod(x)) is the same as   log(prod(x)^(1/length(x)))
    # sum(log(x)) is the same as log(prod(x))
    # which is the same as:
    # which is the same as:
    # mean(log(x), na.rm = na.rm) is the same as (1/length(x)) * sum(log(x))
    geo = exp(mean(log(x), na.rm = na.rm))
    geo
}

```

Hint: use the `apply` function; you can combine it with the `sweep` function but you don't need to

1. Calculate the geometric mean for each row in the count matrix
```{r}

geo <- apply(as.matrix(data),1,geomean)
```
2. Divide each row by the row's geometric mean
```{r}

div <- apply(data,2,"/",geo)

```

3. Take the median value for each column -- these are your size factors, one for each sample
```{r}

sf <- apply(div,2,function(x){m = median(x[is.finite(x)])})

```

4. Divide each sample by its size factor.

Sweep is a function that allows you to apply a function to a margin of an array. In this case, we are dividing each column by the size factor for that column. The `sweep` function takes the array, the margin to apply the function to (2 = columns), the size factor, and the function to apply (`/`).
```{r}

norm <- sweep(data,2,sf,FUN = "/")

```

**Normalized Counts**

**Exercise** points = +1

Determine the normalized counts for your gene of interest, PD1, given the raw counts and size factors below.

NOTE: You will need to run the code below to generate the raw counts dataframe (PD1) and the size factor vector (size_factors), then use these objects to determine the normalized counts values:


```{r}
# Raw counts for PD1
PD1 <- c(21, 58, 17, 97, 83, 10)
names(PD1) <- paste0("Sample", 1:6)
PD1 <- data.frame(PD1)
PD1 <- t(PD1)

# Size factors for each sample
size_factors <- c(1.32, 0.70, 1.04, 1.27, 1.11, 0.85)
```

Normalized counts:
```{r}

# Your code here

```

### Count normalization of Mov10 dataset

#### 1. Match the metadata and counts data
```{r}
### Check that sample names match in both files
all(colnames(data) %in% rownames(meta))
all(colnames(data) == rownames(meta))
```

The colnames of our data don't match the rownames of our metadata so we need to reorder them. We can use the `match` function:
```{r}

idx <- match(rownames(meta),colnames(data))
data <- data[,idx]

all(colnames(data) == rownames(meta))
```

**Exercise** points = +2

Suppose we had sample names matching in the counts matrix and metadata file, but they were out of order. Write the line(s) of code required to create a new matrix with columns ordered such that they were identical to the row names of the metadata.
```{r, eval = FALSE}

# Your code here

```

#### 2. Create DESEq2 object
```{r}

dds <- DESeqDataSetFromMatrix(countData = data, colData = meta, design = ~ sampletype)

```

You can use DESeq-specific functions to access the different slots and retrieve information, if you wish. For example, suppose we wanted the original count matrix we would use counts():
```{r}

head(counts(dds[,1:5]))

colData(dds)

colData(dds)$sampletype

levels(colData(dds)$sampletype)

```

As we go through the workflow we will use the relevant functions to check what information gets stored inside our object. We can also run:
```{r}
slotNames(dds)
```

#### 3. Generate the Mov10 normalized counts


To perform the **median of ratios method** of normalization, DESeq2 has a single `estimateSizeFactors()` function that will generate size factors for us. We will use the function in the example below, but **in a typical RNA-seq analysis this step is automatically performed by the `DESeq()` function**, which we will see later.
```{r}
dds <- estimateSizeFactors(dds)
```

By assigning the results back to the dds object we are filling in the slots of the DESeqDataSet object with the appropriate information. We can take a look at the normalization factor applied to each sample using:
```{r}
sizeFactors(dds)
```

Now, to retrieve the normalized counts matrix from dds, we use the counts() function and add the argument normalized = TRUE.
```{r}
normalized_counts <- counts(dds, normalized = TRUE)
```

We can save this normalized data matrix to file for later use:
```{r}
write.table(normalized_counts, file = "data/normalized_counts.txt", sep = "\t")

# it's always good to save our results, in case we forget to save objects
save.image()
# saves all objects in session/eenvironment
```

## DGE QC analysis

**.md file = 03-DGE_QC_analysis.md**

To improve the distances/clustering for the PCA and heirarchical clustering visualization methods, we need to moderate the variance across the mean by applying the rlog transformation to the normalized counts.

The rlog transformation of the normalized counts is only necessary for these visualization methods during this quality assessment. We will not be using these tranformed counts downstream:
```{r}
### Transform counts for data visualization
rld <- rlog(dds, blind = TRUE)
```

We use this object to plot the PCA and heirarchical clustering figures for quality assessment.

#### Principal components analysis (PCA)

Principal Component Analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset (dimensionality reduction). The take home message for our purposes is that **if two samples have similar levels of expression for the genes that contribute significantly to the variation represented by PC1, they will be plotted close together on the PC1 axis.** Therefore, we would expect that biological replicates to have similar scores (since the same genes are changing) and cluster together on PC1 and/or PC2, and the samples from different treatment groups to have different score. This is easiest to understand by visualizing example PCA plots.

**Exercise** points = +7

The figure below was generated from a time course experiment with sample groups ‘Ctrl’ and ‘Sci’ and the following timepoints: 0h, 2h, 8h, and 16h.

![Alt text](img/PCA_example3.png){ width=600 }

**Determine the sources explaining the variation represented by PC1 and PC2.** 

  - Ans: 

**Do the sample groups separate well?** 

  - Ans: 

**Do the replicates cluster together for each sample group?** 

  - Ans: 

**Are there any outliers in the data?** 

  - Ans: 

**Should we have any other concerns regarding the samples in the dataset?**

  - Ans: 
  
```{r}
### Plot PCA
plotPCA(rld, intgroup = "sampletype")
```

**What does this plot tell you about the similarity of samples?** 

  - Ans: 

**Does it fit the expectation from the experimental design?** 

  - Ans: 

By default the function uses the top 500 most variable genes. You can change this by adding the `ntop` argument and specifying how many genes you want to use to draw the plot.

#### Hierarchical Clustering


We will be using the `pheatmap()` function from the pheatmap package for heatmaps. This function requires a matrix/dataframe of numeric values as input, and so the first thing we need to is retrieve that information from the rld object:
```{r}

### let's look at the structure of rld.
class(rld)
slotNames(rld)
### we can extract the rlog matrix from the object using the `assay` function:
###
rld_mat <- assay(rld)

```

Then we need to compute the pairwise correlation values for samples. We can do this using the `cor()` function:
```{r}
### Compute pairwise correlation values
rld_cor <- cor(rld_mat)    ## cor() is a base R function

head(rld_cor[,1:5])   ## check the output of cor(), make note of the rownames and colnames

min(rld_cor) ## we can see our samples are highly correlated
```

And now to plot the correlation values as a heatmap:
```{r}
### Plot heatmap
pheatmap(rld_cor)
```

**Exercise** points = +3

The pheatmap function has a number of different arguments that we can alter from default values to enhance the aesthetics of the plot. Try adding the arguments `color`, `border_color`, `fontsize_row`, `fontsize_col`, `show_rownames` and `show_colnames` How does your plot change? Take a look through the help pages (?pheatmap) and identify what each of the added arguments is contributing to the plot.
```{r}
display.brewer.all()

heat.colors <- brewer.pal(9, "Blues")

# Your code here

```

- Ans: 

## DGE analysis workflow

**.md file = 04_DGE_DESeq2_analysis.md**

### Running DESeq2

#### Design formula

A design formula tells the statistical software the known sources of variation to control for, as well as, the factor of interest to test for during differential expression testing. For example, let's look at the design formula for our count matrix:
```{r}
design(dds)
```

As another example, suppose you have the following metadata:

![Alt text](img/meta_example.png){ width=300 }
If you want to examine the expression differences between treatments, and you know that major sources of variation include sex and age, then your design formula would be:

```{r}
design <- ~ sex + age + treatment
```

**Exercise** points = +3

1. Suppose you wanted to study the expression differences between the two age groups in the metadata shown above, and major sources of variation were `sex` and `treatment`, how would the design formula be written?


```{r, eval = FALSE}

# Your code here

```

2. Based on our Mov10 metadata dataframe, which factors could we include in our design formula?

  - Ans: 

3. What would you do if you wanted to include a factor in your design formula that is not in your metadata?

  - Ans: 


#### MOV10 DE analysis

To get our differential expression results from our raw count data, we only need to run 2 lines of code!
```{r}
## Create DESeq object
dds <- DESeqDataSetFromMatrix(countData = data, colData = meta, design = ~ sampletype)
```

Then, to run the actual differential expression analysis, we use a single call to the function DESeq().
```{r}
## Run analysis
dds <- DESeq(dds)
```

### DESeq2 differential gene expression analysis workflow

Everything from normalization to linear modeling was carried out by the use of a single function!

With the 2 lines of code above, we just completed the workflow for the differential gene expression analysis with DESeq2. The steps in the analysis are output below:

![Alt text](img/deseq2_workflow_separate.png){ width=200 }

#### Step 1: Estimate size factors

MOV10 DE analysis: examining the size factors
```{r}
## Check the size factors
sizeFactors(dds)
```

Take a look at the total number of reads for each sample:
```{r}
## Total number of raw counts per sample
colSums(counts(dds, normalized = FALSE))
```

**How do the numbers correlate with the size factor?**
```{r}
cor(colSums(counts(dds, normalized = FALSE)),sizeFactors(dds))
```

- Ans: they are highly correlated

#### Step 2: Estimate gene-wise dispersion**

Dispersion is a measure of spread or variability in the data. DESeq2 uses a specific measure of dispersion (α) related to the mean (μ) and variance of the data: $Var = μ + α*μ^2$. For genes with moderate to high count values, the square root of dispersion will be equal to the coefficient of variation (`σ/ μ`). So 0.01 dispersion means 10% variation around the mean expected across biological replicates.

We can make a rough estimate of the gene-wise dispersions using this formula.
We know that:

$$\sigma^2 = {\mu + \alpha*}{\mu^2}$$

So the dispersion is equal to:
$$\alpha = \frac{\sigma^2 - \mu}{\mu^2}$$

```{r}

norm.cts <- counts(dds,normalized = TRUE)
mn <- rowMeans(norm.cts)
mn = mn[order(mn)]
mn <- mn[mn != 0]

v <- rowVars(norm.cts)
names(v) = rownames(norm.cts)

v = v[names(mn)]
```

For genes with moderate to high count values, the square root of dispersion will be equal to the coefficient of variatiomn (`σ / μ`).

Let's try a relatively low mean

To calculate the dispersion, v has to be greater than mu otherwise the disp will be negative

```{r}

wv = which(v > mn)
var <- v[wv][1]
mu <- mn[wv][1]

disp <-  (var - mu)/mu^2

sqrt(var)/mu

sqrt(disp)
```

So the approximation doesn't work very well here. Now let's try a high mean:

```{r}
var <- v[wv][length(wv)]
mu <- mn[wv][length(wv)]

disp <- (var - mu)/mu^2

# approximation for the square root of the dispersion
sqrt(var)/mu
# actual sqrt disp
sqrt(disp)
```

Now the approximation is pretty good. The larger the value of the mean, the better the approximation.

What does the DESeq2 dispersion represent?

The DESeq2 dispersion estimates are inversely related to the mean and directly related to variance. Based on this relationship, the dispersion is higher for small mean counts and lower for large mean counts.

How does the dispersion relate to our model?

To accurately model sequencing counts, we need to generate accurate estimates of within-group variation (variation between replicates of the same sample group) for each gene. With only a few (3-6) replicates per group, the estimates of variation for each gene are often unreliable (due to the large differences in dispersion for genes with similar means).

To address this problem, DESeq2 shares information across genes to generate more accurate estimates of variation based on the mean expression level of the gene using a method called ‘shrinkage’. DESeq2 assumes that genes with similar expression levels have similar dispersion.

Estimating the dispersion for each gene separately:

To model the dispersion based on expression level (mean counts of replicates), the dispersion for each gene is estimated using maximum likelihood estimation. In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data. This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable. In other words, given the count values of the replicates, the most likely estimate of dispersion is calculated.

#### Step 3: Fit curve to gene-wise dispersion estimates

The next step in the workflow is to fit a curve to the dispersion estimates for each gene. The idea behind fitting a curve to the data is that different genes will have different scales of biological variability, but, over all genes, there will be a distribution of reasonable estimates of dispersion.

#### Step 4: Shrink gene-wise dispersion estimates toward the values predicted by the curve

The curve allows for more accurate identification of differentially expressed genes when sample sizes are small, and the strength of the shrinkage for each gene depends on:

- how close gene dispersions are from the curve
- sample size (more samples = less shrinkage)

Dispersion plots are a good way to examine your data to ensure it is a good fit for the DESeq2 model.

##### MOV10 DE analysis: exploring the dispersion estimates and assessing model

Let’s take a look at the dispersion estimates for our MOV10 data:
```{r}
## Plot dispersion estimates
plotDispEsts(dds)
```

Since we have a small sample size, for many genes we see quite a bit of shrinkage.

**Exercise** points = +1

**Do you think our data are a good fit for the model?**

- Ans: 

## Model fitting

**.md file = 05_DGE_DESeq2_analysis2**

### Generalized Linear Model fit for each gene
 
#### Creating contrasts

To indicate to DESeq2 the two groups we want to compare, we can use contrasts. Contrasts are then provided to DESeq2 to perform differential expression testing using the Wald test. Contrasts can be provided to DESeq2 a couple of different ways:

1. Do nothing. Automatically DESeq2 will use the base factor level of the condition of interest as the base for statistical testing. The base level is chosen based on alphabetical order of the levels.

2. In the results() function you can specify the comparison of interest, and the levels to compare. The level given last is the base level for the comparison. The syntax is given below:
```{r, eval = FALSE}
# DO NOT RUN!
contrast <- c("condition", "level_to_compare", "base_level")
results(dds, contrast = contrast, alpha = alpha_threshold)
```

##### MOV10 DE analysis: contrasts and Wald tests

We have three sample classes so we can make three possible pairwise comparisons:

1. Control vs. Mov10 overexpression
2. Control vs. Mov10 knockdown
3. Mov10 knockdown vs. Mov10 overexpression

**We are really only interested in #1 and #2 from above**. Using the design formula we provided `~ sampletype`, indicating that this is our main factor of interest.

#### Building the results table

Defining the contrasts and extracting the results table is done using the `results()` function. The `results()` function will return a results table with the log2 fold changes, standard errors, p-values, and p-adjusted values for each gene. The results table is stored in a `DESeqResults` object.

For the coef argument of`lfcShrink()` we can use the coefficient names from the `resultsNames()` or provide a number based on the order in `resultsNames()`.
```{r}

contrast_oe <- c("sampletype", "MOV10_overexpression", "control")

res_tableOE_unshrunken <- results(object = dds, contrast = contrast_oe, alpha = 0.05)

resultsNames(dds)

res_tableOE <- lfcShrink(dds, coef = "sampletype_MOV10_overexpression_vs_control", res = res_tableOE_unshrunken, type = "apeglm")

# We will save these results for later use in the data directory using the following command:

saveRDS(res_tableOE, file = "data/res_tableOE.rds")
```

**The order of the names determines the direction of fold change that is reported.** The name provided in the second element is the level that is used as baseline. So for example, if we observe a log2 fold change of -2 this would mean the gene expression is lower in Mov10_oe relative to the control.**

#### MA Plot

A plot that can be useful to exploring our results is the MA plot. The MA plot shows the mean of the normalized counts versus the log2 foldchanges for all genes tested. The genes that are significantly DE are colored to be easily identified. This is also a great way to illustrate the effect of LFC shrinkage. The DESeq2 package offers a simple function to generate an MA plot.

**Let's start with the unshrunken results:**

Viewing the results:

`par` is a base R function that allows you to set graphical parameters. In this case, we are setting the layout of the plots to be 1 row and 2 columns. This means that the next two plots will be displayed side by side.
```{r}

par(mfrow = c(1,2))
plotMA(res_tableOE_unshrunken, ylim = c(-2,2))

```

**And now the shrunken results:**
We see that the shrunken log2 fold changes are more conservative than the unshrunken log2 fold changes. This is because the shrunken log2 fold changes are moderated towards zero. This is especially useful when we have a small number of replicates.

Set `par(mfrow = c(1,1))` to reset the layout to a single plot.
```{r}

plotMA(res_tableOE, ylim = c(-2,2))
par(mfrow = c(1,1))

```

This plot allows us to evaluate the magnitude of fold changes and how they are distributed relative to mean expression. 

##### MOV10 DE analysis: results exploration

The results table looks very much like a dataframe and in many ways it can be treated like one (i.e when accessing/subsetting data). However, it is important to recognize that it is actually stored in a `DESeqResults` object. When we start visualizing our data, this information will be helpful.
```{r}
class(res_tableOE)
```

Let’s go through some of the columns in the results table to get a better idea of what we are looking at. To extract information regarding the meaning of each column we can use mcols():
```{r}

mcols(res_tableOE, use.names = T)

mcols(res_tableOE, use.names = T)$description
```

```{r}
res_tableOE %>% data.frame() %>% head()
```

If we used the `p-value` directly from the Wald test with a significance cut-off of p < 0.05, that means there is a 5% chance it is a false positives. Each p-value is the result of a single test (single gene). The more genes we test, the more we inflate the false positive rate. **This is the multiple testing problem.**

In DESeq2, the p-values attained by the Wald test are corrected for multiple testing using the Benjamini and Hochberg method by default. There are options to use other methods in the `results()` function. The p-adjusted values should be used to determine significant genes.

##### MOV10 DE analysis: Control versus Knockdown

Now that we have results for the overexpression results, let's do the same for the **Control vs. Knockdown samples**. Use contrasts in the `results()` to extract a results table and store that to a variable called `res_tableKD`.

Define the contrast, extract the results table, and shrink the log2 fold changes.

Here for the `coef` argument of`lfcShrink()` we provide a number based on the order in `resultsNames()`.
```{r}

contrast_kd <-  c("sampletype", "MOV10_knockdown", "control")

res_tableKD_unshrunken <- results(object = dds, contrast = contrast_kd, alpha = 0.05)


resultsNames(dds)

res_tableKD <- lfcShrink(dds, coef = 2, res = res_tableKD_unshrunken)

# We will save these results for later use in the data directory using the following command:

saveRDS(res_tableKD, file = "data/res_tableKD.rds")

# just for security, save all our objects in ".RData" again:
save.image()
```

Let's look at the number of genes below the standard p-adjusted value 0.05:
```{r}

table(res_tableKD$padj < 0.05)

table(res_tableOE$padj < 0.05)
```

### Summarizing results

To summarize the results table, a handy function in DESeq2 is `summary()`. Confusingly it has the same name as the function used to inspect data frames. This function when called with a DESeq results table as input, will summarize the results using the alpha threshold: FDR < 0.05 (padj/FDR is used even though the output says `p-value < 0.05`).

```{r}

summary(res_tableOE)

```

#### Extracting significant differentially expressed genes

What we noticed is that the FDR threshold on it's own doesn't appear to be reducing the number of significant genes. With large significant gene lists it can be hard to extract meaningful biological relevance. To help increase stringency, one can also **add a fold change threshold**.
```{r}
### Set thresholds

padj.cutoff <- 0.05

lfc.cutoff <- 0.58 ## change in expression of 1.5
```

The lfc.cutoff is set to 0.58; remember that we are working with log2 fold changes so this translates to an actual fold change of 1.5 which is pretty reasonable.

We can easily subset the results table to only include those that are significant using the filter() function, but first we will convert the results table into a tibble:
```{r}

res_tableOE_tb <- res_tableOE %>%
  data.frame() %>%
  rownames_to_column(var = "gene") %>%
  as_tibble()
```

Now we can subset that table to only keep the significant genes using our pre-defined thresholds:
```{r}

sigOE <- res_tableOE_tb %>%
        dplyr::filter(padj < padj.cutoff & 
                      abs(log2FoldChange) > lfc.cutoff)

```

**Exercise** points = +3

**How many genes are differentially expressed in the Overexpression compared to Control, given our criteria specified above? Does this reduce our results?** 
```{r}

# Your code here

```
  - Ans: 

**Does this reduce our results?** 
```{r}
# Your code here
```
  - Ans: 

Using the same thresholds as above (`padj.cutoff < 0.05` and `lfc.cutoff = 0.58)`, subset `res_tableKD` to report the number of genes that are up- and down-regulated in Mov10_knockdown compared to control.
```{r}

res_tableKD_tb <- res_tableKD %>%
  data.frame() %>%
  rownames_to_column(var = "gene") %>%
  as_tibble()

sigKD <- res_tableKD_tb %>%
         dplyr::filter(padj < padj.cutoff & 
         abs(log2FoldChange) > lfc.cutoff)

# We'll save this object for use in the homework
saveRDS(sigKD,"data/sigKD.rds")
```

**How many genes are differentially expressed in the Knockdown compared to Control?**
```{r}
# Your code here
```
  - Ans: 


## Visualizing rna-seq results

**.md file = 06_DGE_visualizing_results.md**

Let’s start by loading a few libraries (if not already loaded):
```{r}


# load libraries
library(tidyverse)
library(ggplot2)
library(ggrepel)
library(RColorBrewer)
library(DESeq2)
library(pheatmap)

# we may want to load our objects again. here:
# load(".RData")
```

When we are working with large amounts of data it can be useful to display that information graphically to gain more insight.

Let’s create tibble objects from the meta and normalized_counts data frames before we start plotting. This will enable us to use the tidyverse functionality more easily.

Basically, we are taking the rownames and adding them as a field in the tibble/data.frame.
```{r}

# Create a tibble for meta data
mov10_meta <- meta %>% 
  rownames_to_column(var = "samplename") %>% 
  as_tibble()
        
# you might to read in normalized_counts if it is not in your current session:



normalized_counts <-     read.delim("data/normalized_counts.txt", row.names = 1)

# then make sure the colnames of normalized_counts are the same as the mov10_meta$sampname

all(mov10_meta$samplename == colnames(normalized_counts))


# Create a tibble for normalized_counts
normalized_counts <- normalized_counts %>% 
  data.frame() %>%
  rownames_to_column(var = "gene") %>% 
  as_tibble()



```

### Plotting signicant DE genes

One way to visualize results would be to simply plot the expression data for a handful of genes. We could do that by picking out specific genes of interest or selecting a range of genes.

#### Using DESeq2 `plotCounts()` to plot expression of a single gene

To pick out a specific gene of interest to plot, for example Mov10, we can use the `plotCounts()` from DESeq2:
```{r}

# Plot expression for single gene

plotCounts(dds, gene = "MOV10", intgroup = "sampletype") 

# we can give it some color and filled points:

sampletype = as.factor(mov10_meta$sampletype)

library(RColorBrewer)

display.brewer.all()

col = brewer.pal(8,"Dark2")
palette(col)

plotCounts(dds, gene = "MOV10", intgroup = "sampletype",col = as.numeric(sampletype),pch = 19) 
```

#### Using ggplot2 to plot expression of a single gene

If you wish to change the appearance of this plot, we can save the output of `plotCounts()` to a variable specifying the `returnData = TRUE` argument, then use `ggplot()`:
```{r}

# Save plotcounts to a data frame object
d <- plotCounts(dds, gene = "MOV10", intgroup = "sampletype", returnData = TRUE)

# Plotting the MOV10 normalized counts, using the samplenames (rownames of d as labels)
ggplot(d, aes(x = sampletype, y = count, color = sampletype)) + 
  geom_point(position = position_jitter(w = 0.1,h = 0)) +
  geom_text_repel(aes(label = rownames(d))) + 
  theme_bw() +
  ggtitle("MOV10") +
  theme(plot.title = element_text(hjust = 0.5))
```

#### Using `ggplot2` to plot multiple genes (e.g. top 20)

Often it is helpful to check the expression of multiple genes of interest at the same time. This often first requires some data wrangling.

We are going to plot the normalized count values for the **top 20 differentially expressed genes (by padj values)**.
```{r}

## Order results by padj values
top20_sigOE_genes <- res_tableOE_tb %>% 
        arrange(padj) %>% 	
#Arrange rows by padj values
        pull(gene) %>% 		
#Extract character vector of ordered genes
        head(n = 20) 		
#Extract the first 20 genes
```

Then, we can extract the normalized count values for these top 20 genes:
```{r}
## normalized counts for top 20 significant genes
top20_sigOE_norm <- normalized_counts %>%
        dplyr::filter(gene %in% top20_sigOE_genes)
```

Now that we have the normalized counts for each of the top 20 genes for all 8 samples, to plot using `ggplot()`, we need to `pivot_longer` top20_sigOE_norm from a wide format to a long format so the counts for all samples will be in a single column to allow us to give ggplot the one column with the values we want it to plot.

The `pivot_longer()` function in the **tidyr** package will perform this operation and will output the normalized counts for all genes for *Mov10_oe_1* listed in the first 20 rows, followed by the normalized counts for *Mov10_oe_2* in the next 20 rows, so on and so forth.

![Alt text](img/melt_wide_to_long_format.png){ width=800 }


```{r}
# Pivoting the columns to have normalized counts to a single column

pivoted_top20_sigOE <- top20_sigOE_norm %>%
  pivot_longer(colnames(top20_sigOE_norm)[2:9], names_to = "samplename", values_to = "normalized_counts")

## check the column header in the "pivoted" data frame
head(pivoted_top20_sigOE)
```

Now, if we want our counts colored by sample group, then we need to combine the metadata information with the melted normalized counts data into the same data frame for input to `ggplot()`. We can do this using the `inner_join()` function from the **dplyr** package. This function will merge the two data frames by the column name in the first data frame that matches a column name in the second data frame.
```{r}
pivoted_top20_sigOE <- inner_join(mov10_meta, pivoted_top20_sigOE, by = "samplename")
```

Now that we have a data frame in a format that can be utilised by ggplot easily, let’s plot!
```{r}
## plot using ggplot2
ggplot(pivoted_top20_sigOE) +
        geom_point(aes(x = gene, y = normalized_counts, color = sampletype)) +
        scale_y_log10() +
        xlab("Genes") +
        ylab("log10 Normalized Counts") +
        ggtitle("Top 20 Significant DE Genes") +
        theme_bw() +
      	theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      	theme(plot.title = element_text(hjust = 0.5))
```

### Heatmap

In addition to plotting subsets, we could also extract the normalized values of *all* the significant genes and plot a heatmap of their expression using `pheatmap()`.
```{r}

sigOE = readRDS("data/sigOE.rds")
### Extract normalized expression for significant genes from the OE and control samples c(2:4,7:9), and set the gene column (1) to row names

norm_OEsig <- normalized_counts[,c(1,2:4,7:9)] %>% 
              filter(gene %in% sigOE$gene) %>% 
	      data.frame() %>%
	      column_to_rownames(var = "gene") 
```

Now let’s draw the heatmap using pheatmap:
```{r}
### Annotate our heatmap (optional)

annotation <- mov10_meta %>% 
	dplyr::select(samplename, sampletype) %>% 
	data.frame(row.names = "samplename")

### Set a color palette
heat_colors <- brewer.pal(6, "YlOrRd")

### Run pheatmap
pheatmap(norm_OEsig, 
         color = heat_colors, 
         cluster_rows = T, 
         show_rownames = F,
         annotation = annotation, 
         border_color = NA, 
         fontsize = 10, 
         scale = "row", 
         fontsize_row = 10, 
         height = 20)
```

#### Volcano plot

The above plot would be great to look at the expression levels of a good number of genes, but for more of a global view there are other plots we can draw. A commonly used one is a volcano plot; in which you have the log transformed adjusted p-values plotted on the y-axis and log2 fold change values on the x-axis.

To generate a volcano plot (which you have the log transformed adjusted p-values plotted on the y-axis and log2 fold change values on the x-axis), we first need to have a column in our results data indicating whether or not the gene is considered differentially expressed based on p-adjusted values.
```{r}

## Obtain logical vector where TRUE values denote padj values < 0.05 and fold change > 1.5 in either direction

res_tableOE_tb <- res_tableOE_tb %>% 
                  mutate(threshold_OE = padj < 0.05 & abs(log2FoldChange) >= 0.58)
```

Now we can start plotting:
```{r}


## Volcano plot

ggplot(res_tableOE_tb) +
        geom_point(aes(x = log2FoldChange, 
        y = -log10(padj), colour = threshold_OE)) +
        ggtitle("Mov10 overexpression") +
        xlab("log2 fold change") + 
        ylab("-log10 adjusted p-value") +
        #scale_y_continuous(limits = c(0,50)) +
        theme(legend.position = "none",
        plot.title = element_text(size = rel(1.5),             hjust = 0.5),
        axis.title = element_text(size = rel(1.25)))
```

What if we also wanted to know where the top 10 genes (lowest padj) in our DE list are located on this plot? We could label those dots with the gene name on the Volcano plot using `geom_text_repel()`.

First, we need to order the res_tableOE tibble by padj, and add an additional column to it, to include on those gene names we want to use to label the plot.
```{r}

## Create a column to indicate which genes to label
res_tableOE_tb <- res_tableOE_tb %>% arrange(padj) %>% mutate(genelabels = "")

res_tableOE_tb$genelabels[1:10] <- res_tableOE_tb$gene[1:10]

head(res_tableOE_tb)
```

Next, we plot it as before with an additional layer for `geom_text_repel()` wherein we can specify the column of gene labels we just created.
```{r}

ggplot(res_tableOE_tb, aes(x = log2FoldChange, 
        y = -log10(padj))) +
        geom_point(aes(colour = threshold_OE)) +
        geom_text_repel(aes(label = genelabels)) +
        ggtitle("Mov10 overexpression") +
        xlab("log2 fold change") + 
        ylab("-log10 adjusted p-value") +
        theme(legend.position = "none",
        plot.title = element_text(size = rel(1.5),             hjust = 0.5),
        axis.title = element_text(size = rel(1.25))) 
```

## Summary of differential expression analysis workflow

**.md file = 07-DGE_summarizing_workflow.md**

```{r, message = FALSE}
## Setup
### Bioconductor and CRAN libraries used
library(DESeq2)
```
We have detailed the various steps in a differential expression analysis workflow, providing theory with example code. To provide a more succinct reference for the code needed to run a DGE analysis, we have summarized the steps in an analysis below:

### 1. Import data into dds object:
```{r, eval = FALSE}

# Check that the row names of the metadata equal the column names of the **raw counts** data
all(colnames(raw_counts) == rownames(metadata))

# Create DESeq2Dataset object
dds <- DESeqDataSetFromMatrix(countData = raw_counts, colData = metadata, design = ~ condition)

```

### 2. Exploratory data analysis (PCA & heirarchical clustering) - identifying outliers and sources of variation in the data:
```{r, eval = FALSE}

# Transform counts for data visualization
rld <- rlog(dds, blind = TRUE)

# Plot PCA
plotPCA(rld, intgroup = "sampletype")

# Extract the rlog matrix from the object
rld_mat <- assay(rld)

# Compute pairwise correlation values
rld_cor <- cor(rld_mat)

# Plot heatmap
pheatmap(rld_cor)
```

### 3. Run DESeq2:
```{r, eval = FALSE}

# **Optional step** - Re-create DESeq2 dataset if the design formula has changed after QC analysis in include other sources of variation

dds <- DESeqDataSetFromMatrix(countData = raw_counts, colData = metadata, design = ~ condition)

# Run DESeq2 differential expression analysis
dds <- DESeq(dds)

#  **Optional step** - Output normalized counts to save as a file to access outside RStudio
    normalized_counts <- counts(dds, normalized = TRUE)
    
write.table(normalized_counts, file = "data/normalized_counts.txt", sep = "\t", quote = F, col.names = NA)

```

### 4. Check the fit of the dispersion estimates:
```{r, eval = FALSE}

# Plot dispersion estimates
plotDispEsts(dds)
```

### 5. Create contrasts to perform Wald testing on the shrunken log2 foldchanges between specific conditions:
```{r, eval = FALSE}

# Output results of Wald test for contrast
contrast <- c("condition", "level_to_compare", "base_level")

res <- results(dds, contrast = contrast)

coef = resultsNames(dds)

res_tableOE <- lfcShrink(dds, coef = coef[2], res = res, type = "apeglm")
```

### 6. Output significant results:
```{r, eval = FALSE}
### Set thresholds
padj.cutoff <- 0.05
lfc.cutoff <- 0.58 ## change in expression of 1.5

# Turn the results object into a data frame
res_df <- res %>%
  data.frame() %>%
  rownames_to_column(var = "gene") 

# Subset the significant results
sig_res <- dplyr::filter(res_df, padj < padj.cutoff & abs(log2FoldChange) > lfc.cutoff)
```

### 7. Visualize results: volcano plots, heatmaps, normalized counts plots of top genes, etc.

### 8. Make sure to output the versions of all tools used in the DE analysis:
```{r}
sessionInfo()
```

**Exercise/Homework: modify this file to analyze the MOV dataset, starting with Mov10_full_counts.txt in your data folder. Compare the "MOV10_knockdown" to the "control". Include a heatmap and a volcano plot** points +10

## Functional analysis

**.md file = 08-GO_enrichment_analysis.md**

Functional analysis tools are useful in interpreting resulting DGE gene lists from RNAseq, and fall into three main types:

1. Over-representation analysis
2. Functional class scoring
3. Pathway topology

### Over-representation analysis

To determine whether any GO terms are over-represented in a significant gene list, the probability of the observed proportion of genes associated with a specific term is compared to the probability of the background set of genes belonging to the same term. This statistical test is known as the "hypergeometric test".

We will be using [clusterProfiler](http://bioconductor.org/packages/release/bioc/html/clusterProfiler.html) 

### clusterProfiler

```{r, message = FALSE}
# you may have to install some of these libraries; use 
# BiocManager::install(c("org.Hs.eg.db","clusterProfiler","enrichplot","fgsea"))

library(org.Hs.eg.db)
library(clusterProfiler)
library(tidyverse)
library(enrichplot)
library(fgsea) 

```

#### Running clusterProfiler

```{r}

res_tableOE = readRDS("data/res_tableOE.rds")

res_tableOE_tb <- res_tableOE %>%
data.frame() %>%
rownames_to_column(var = "gene") %>%
dplyr::filter(!is.na(log2FoldChange))  %>% as_tibble()

```

To perform the over-representation analysis, we need a list of background genes and a list of significant genes. For our background dataset we will use all genes tested for differential expression (all genes in our results table). For our significant gene list we will use genes with p-adjusted values less than 0.05 (we could include a fold change threshold too if we have many DE genes).
```{r}
## background set of ensgenes
allOE_genes <- res_tableOE_tb$gene

sigOE = dplyr::filter(res_tableOE_tb, padj < 0.05)

sigOE_genes = sigOE$gene

```

Now we can perform the GO enrichment analysis and save the results:
```{r}
## Run GO enrichment analysis
ego <- enrichGO(gene = sigOE_genes,
                universe = allOE_genes,
                keyType = "SYMBOL",
                OrgDb = org.Hs.eg.db,
                minGSSize = 20,
                maxGSSize = 300,
                ont = "BP",
                pAdjustMethod = "BH",
                qvalueCutoff = 0.05,
                readable = TRUE)

## Output results from GO analysis to a table
cluster_summary <- data.frame(ego)

## make sure you have a results directory
write.csv(cluster_summary, "results/clusterProfiler_Mov10oe.csv")

```

#### Visualizing clusterProfiler results

**dotplot**

The dotplot shows the number of genes associated with the first 50 terms (size) and the p-adjusted values for these terms (color). This plot displays the top 50 genes by gene ratio (# genes related to GO term / total number of sig genes), not p-adjusted value.
```{r}
## Dotplot
## 
dotplot(ego, showCategory = 50)
```
To save the figure, click on the Export button in the RStudio Plots tab and Save as PDF....set PDF size to 8 x 14 to give a figure of appropriate size for the text labels

**enrichment GO plot**

The next plot is the enrichment GO plot, which shows the relationship between the top 50 most significantly enriched GO terms (padj.), by grouping similar terms together. The color represents the p-values relative to the other displayed terms (brighter red is more significant) and the size of the terms represents the number of genes that are significant from our list.

This plot is useful because it serves to collapse the GO terms into functional categories by showing the overlap between GO terms.
```{r}
## Enrichmap clusters the 50 most significant (by padj) GO terms to visualize relationships between terms

pwt <- pairwise_termsim(
ego,
method = "JC",
semData = NULL,
showCategory = 50
)

emapplot(pwt, showCategory = 50)
```

To save the figure, click on the Export button in the RStudio Plots tab and Save as PDF.... In the pop-up window, change the PDF size to 24 x 32 to give a figure of appropriate size for the text labels.

Finally, the category netplot shows the relationships between the genes associated with the top five most significant GO terms and the fold changes of the significant genes associated with these terms (color). The size of the GO terms reflects the pvalues of the terms, with the more significant terms being larger. This plot is particularly useful for hypothesis generation in identifying genes that may be important to several of the most affected processes.

**netplot**
```{r}
## To color genes by log2 fold changes, we need to extract the log2 fold changes from our results table creating a named vector
OE_foldchanges <- sigOE$log2FoldChange

names(OE_foldchanges) <- sigOE$gene


## Cnetplot details the genes associated with one or more terms - by default gives the top 5 significant terms (by padj)
cnetplot(ego,
         categorySize = "pvalue",
         showCategory = 5,
         foldChange = OE_foldchanges,
         vertex.label.font = 6)

```

**Again, to save the figure**, click on the Export button in the RStudio Plots tab and Save as PDF.... Change the PDF size to 24 x 32 to give a figure of appropriate size for the text labels.

### Gene set enrichment analysis (GSEA)

#### GSEA using clusterProfiler

GSEA uses the entire list of log2 fold changes from all genes. It is based on looking for enrichment of genesets among the large positive or negative fold changes. Thus, rather than setting an arbitrary threshold to identify ‘significant genes’, all genes are considered in the analysis. The gene-level statistics from the dataset are aggregated to generate a single pathway-level statistic and statistical significance of each pathway is reported.


Extract and name the fold changes:
```{r}
## Extract the foldchanges
foldchanges <- res_tableOE_tb$log2FoldChange

## Name each fold change with the corresponding Entrez ID
names(foldchanges) <- res_tableOE_tb$gene
```

Next we need to order the fold changes in decreasing order. To do this we'll use the `sort()` function, which takes a vector as input. This is in contrast to Tidyverse's `arrange()`, which requires a data frame.
```{r}
## Sort fold changes in decreasing order
foldchanges <- sort(foldchanges, decreasing = TRUE)

head(foldchanges)
```

We can explore the enrichment of BP Gene Ontology terms using gene set enrichment analysis:
```{r}
# GSEA using gene sets associated with BP Gene Ontology terms

gseaGO <- clusterProfiler::gseGO(
  geneList = foldchanges,
  ont = "BP",
  keyType = "SYMBOL",
  eps = 0,
  minGSSize = 20,
  maxGSSize = 300,
  pAdjustMethod = "BH",
  pvalueCutoff = 0.05,
  verbose = TRUE,
  OrgDb = "org.Hs.eg.db",
  by = "fgsea"
)

gseaGO_results <- gseaGO@result

goplot(gseaGO)

gseaplot2(gseaGO, geneSetID = 1:3)
```

We can also use our homemade GO enrichment analysis. To do this we need to load the library GOenrichment:

```{r}

# Uncomment the following if you haven't yet installed GOenrichment.

# devtools::install_github("gurinina/GOenrichment")

library(GOenrichment)

ls("package:GOenrichment")
```

One of the problems with GO enrichment analysis is that the GO annotations are in constant flux. 

Here we can use the GO annotations in `hGOBP.gmt` (downloaded recently) to run GSEA using the `fgsea` package to run GSEA:

```{r}


fgseaRes <-  fgsea::fgseaSimple(pathways = hGOBP.gmt,stats = foldchanges,nperm = 1000,maxSize = 300,minSize = 20)

fgsea <- data.frame(fgseaRes,stringsAsFactors = F)

w = which(fgsea$ES > 0)

fposgsea <- fgsea[w,]

fposgsea <- fposgsea %>% arrange(padj)

```


We are going to compare these results to runing the GO enrichment function `runGORESP`. `runGORESP` uses over-representation analysis to identify enriched GO terms, so we need to define a significance cutoff for the `querySet`.
```{r}
args(runGORESP)

?runGORESP

# we'll define our significance cutoff as 0.58, corresponding to 1.5x change.

# `runGORESP` requires a matrix, so we can turn foldchanges into a matrix using `cbind`:
matx <- cbind(foldchanges,foldchanges)

hresp = GOenrichment::runGORESP(fdrThresh = 0.2, mat = matx, coln = 1, curr_exp = colnames(matx)[1], sig = 0.58,
bp_input = hGOBP.gmt,go_input = NULL, minSetSize = 20,
maxSetSize = 300)

names(hresp$edgeMat)
names(hresp$enrichInfo)
head(hresp$enrichInfo[,c(2,3,4,5,10)])
```

Let's check the overlap between the enriched terms found using `runGORESP` and those found using `fgseaSimple` as they used the same GO term libraries:

```{r}
w = which(fposgsea$padj <= 0.2)

lens <- length(intersect(fposgsea$pathway[w],hresp$enrichInfo$term))

length(w)
dim(hresp$enrichInfo)

percent_overlap <- lens/nrow(hresp$enrichInfo)*100

percent_overlap
```

80%, that's very good, especially because we are using two different GO enrichment methods, over-representation analysis and GSEA. The overlap between these enrichment and the ones using the other GO enrichment tools will be very small because of the differences in the GO annotation libraries.

Now to set up the results for viewing in a network, we use the function `visSetup`, which creates a set of nodes and edges in the network, where nodes are GO terms (node size proportional to FDR score) and edges represent the overlap between GO terms (proportional to edge width). This network analysis is based on [Cytoscape](https://cytoscape.org/), an open source bioinformatics software platform for visualizing molecular interaction networks.

```{r}
vis = visSetup(hresp$enrichInfo,hresp$edgeMat)
names(vis)
```

Now we use runNetwork to view the map: 

```{r}
runNetwork(vis$nodes,vis$edges)
```

This is one of the best visualizations available out of all the GO packages.

There are other gene sets available for GSEA analysis in clusterProfiler (Disease Ontology, Reactome pathways, etc.). In addition, it is possible to supply your own gene set GMT file, such as a GMT for MSigDB called c2.

** The C2 subcollection CGP: Chemical and genetic perturbations. Gene sets that represent expression signatures of genetic and chemical perturbations.**

### Other tools and resources

- [GeneMANIA](http://genemania.org/). GeneMANIA finds other genes that are related to a set of input genes, using a very large set of functional association data curated from the literature. Association data include protein and genetic interactions, pathways, co-expression, co-localization and protein domain similarity.

- [ReviGO](http://revigo.irb.hr/). Revigo is an online GO enrichment tool that allows you to copy-paste your significant gene list and your background gene list. The output is a visualization of enriched GO terms in a hierarchical tree.

- [AmiGO](http://amigo.geneontology.org/amigo). AmiGO is the current official web-based set of tools for searching and browsing the Gene Ontology database.

- [DAVID](http://david.abcc.ncifcrf.gov/tools.jsp). The fold enrichment is defined as the ratio of the two proportions; one is the proportion of genes in your list belong to certain pathway, and the other is the proportion of genes in the background information (i.e., universe genes) that belong to that pathway.

- etc.

